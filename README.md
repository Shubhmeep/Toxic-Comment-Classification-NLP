# NLP Toxic Comment Classification
### Problem Statement: 
Given a comment from social media platform, our task is to identify if it has any toxic content and classify it to belong to one or more of the following categories.
- Toxic
- Angry
- Sad
- Fear
- Joy
- Shame
- Disgust
- Shame
- Neutral 


### Our Approach:
We have devised a prototype that is capable of classifying a comment/text on the basis of above mentioned categories. We have made our own Dataset for this multilabel classification problem by merging multiple pre-existing datasets into one dataset. The dataset has 8 labels that represent the above comment categories, but the project is going to focus on a seventh label that represents the general toxicity of the comments.The project is done with Python and Jupyter notebooks, which are all attached.
- Explore the dataset to get a better picture of how the labels are distributed, how they correlate with each other, and what defines toxic or clean comments or comments from other categories. 
- Create a baseline score with a simple logistic regression classifier. 
- Explore the effectiveness of multiple machine learning approaches and select the best for this problem.
- Using Python web GUI - Streamlit deploy the model.

Disclaimer: The dataset has extremely offensive language that will show up during exploratory data analysis done in the Jupyter notebook itself.


### Algorithms and Techniques:

